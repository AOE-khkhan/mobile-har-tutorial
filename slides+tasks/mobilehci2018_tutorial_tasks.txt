

MobileHCI 2018 tutorial: Machine Learning for Intelligent Mobile User Interfaces using Keras.

Tasks:

## Dataset & sensors

- experiment with different training dataset (e.g., WISDM Actitracker)
- collect Android test set with N subjects (e.g., find sensor logger in Google Play store)
- better visualization of sensor data statistics from Android and MotionNode access + gyr sensors
- experiment with other variables like age

## Preprocessing

- experiment / compare different window sizes
- experiment with different types of sensor reading normalization (report statistics). e.g., feature normalization (z-score, low-pass filters, orientation-invariant transformations, etc.)
- experiment with time series data augmentation

## Network choice & optimization

- experiment with accel (shown already) or gyro only
- experiment with CNN only or LSTM only model
- implement early stopping, grid search
- run cross-val over whole dataset for better deployed model performance

## App UI

- adaptive UI: e.g., increase keyboard size while walking, adjust volume

